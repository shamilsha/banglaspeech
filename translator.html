<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Unified Bidirectional Voice Translator (Android Error Resilient)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <style>
        /* Custom styles for aesthetic appeal and responsiveness */
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f7fafc; /* Light gray background */
            display: flex;
            justify-content: center;
            align-items: flex-start;
            min-height: 100vh;
            padding: 20px;
        }
        .container-card {
            background-color: white;
            padding: 3rem 2rem;
            border-radius: 1.5rem;
            box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.1), 0 8px 10px -6px rgba(0, 0, 0, 0.1);
            max-width: 1000px;
            width: 100%;
            border-top: 5px solid #06B6D4;
        }
        .mic-button {
            transition: all 0.2s ease-in-out;
        }
        .mic-button:hover {
            box-shadow: 0 0 10px rgba(6, 182, 212, 0.5);
        }
        .mic-button.recording {
            animation: pulse-red 1.5s infinite;
            background-color: #EF4444;
            color: white;
        }
        @keyframes pulse-red {
            0% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(239, 68, 68, 0); }
            100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); }
        }
        .speak-button {
            transition: background-color 0.2s;
        }
        .speak-button:hover {
            background-color: #0c8c9e;
        }
        .select-wrapper {
            position: relative;
        }
        .select-wrapper::after {
            content: 'â–¼';
            position: absolute;
            right: 1rem;
            top: 50%;
            transform: translateY(-50%);
            pointer-events: none;
            color: #4a5568;
        }
        .language-select {
            appearance: none;
            padding-right: 2.5rem;
        }
        .loading-indicator {
            display: flex;
            align-items: center;
            justify-content: center;
            color: #06B6D4;
            font-weight: 600;
        }
        .spinner {
            border: 4px solid rgba(0, 0, 0, 0.1);
            border-left-color: #06B6D4;
            border-radius: 50%;
            width: 24px;
            height: 24px;
            animation: spin 1s linear infinite;
            margin-right: 8px;
        }
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
        /* Style for the API toggle switch */
        .toggle-switch-container {
            display: flex;
            align-items: center;
            cursor: pointer;
            user-select: none;
            padding: 10px 0;
            border-radius: 0.5rem;
        }
        .toggle-switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 28px;
            margin-right: 10px;
        }
        .toggle-switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 28px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 20px;
            width: 20px;
            left: 4px;
            bottom: 4px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: #06B6D4;
        }
        input:checked + .slider:before {
            transform: translateX(22px);
        }

        /* Responsive layout for the panels */
        @media (min-width: 768px) {
            .panel-grid {
                grid-template-columns: 1fr 50px 1fr;
            }
        }
    </style>
</head>
<body>

<div class="container-card">
    <h1 class="text-3xl font-bold text-center text-gray-800 mb-2">7-Language Voice Translator (Android Error Resilient)</h1>
    <p class="text-center text-gray-500 mb-6">Translation will auto-speak after your first successful microphone use. Session will stop automatically after 7 seconds.</p>

    <!-- Language Selectors (Source and Target) -->
    <div class="grid grid-cols-2 gap-4 mb-4">
        
        <!-- Source Language Selector (All 7 languages) -->
        <div class="flex flex-col items-center space-y-2">
            <label for="source-language-select" class="text-gray-700 font-medium">Source Language:</label>
            <div class="select-wrapper w-full max-w-xs">
                <select id="source-language-select"
                        class="language-select w-full bg-white border border-gray-300 text-gray-700 py-3 px-4 pr-8 rounded-lg shadow-sm focus:outline-none focus:ring-2 focus:ring-cyan-500 focus:border-cyan-500">
                </select>
            </div>
        </div>

        <!-- Target Language Selector (All 7 languages) -->
        <div class="flex flex-col items-center space-y-2">
            <label for="target-language-select" class="text-gray-700 font-medium">Target Language:</label>
            <div class="select-wrapper w-full max-w-xs">
                <select id="target-language-select"
                        class="language-select w-full bg-white border border-gray-300 text-gray-700 py-3 px-4 pr-8 rounded-lg shadow-sm focus:outline-none focus:ring-2 focus:ring-cyan-500 focus:border-cyan-500">
                </select>
            </div>
        </div>
    </div>
    
    <!-- TTS API Toggle -->
    <div class="flex justify-center mb-8">
        <label class="toggle-switch-container">
            <div class="toggle-switch">
                <input type="checkbox" id="tts-api-toggle">
                <span class="slider"></span>
            </div>
            <span class="text-lg font-bold text-gray-700">Use High-Quality API for Speech</span>
        </label>
    </div>

    <!-- Translation Panels and Controls -->
    <div class="grid grid-cols-1 md:grid-cols-3 gap-6 panel-grid">
        
        <!-- Panel A (Source Text/Input) -->
        <div id="panel-A" class="p-4 bg-gray-50 border border-gray-200 rounded-lg">
            <h2 id="title-A" class="text-xl font-bold text-gray-700 mb-3"></h2>
            <textarea id="text-A"
                      rows="6"
                      class="w-full p-3 border border-gray-300 rounded-lg focus:ring-cyan-500 focus:border-cyan-500 resize-none text-gray-700 font-medium"
                      placeholder="Speak here, or type, to translate..."></textarea>
            
            <div class="flex justify-between items-center mt-3">
                <p id="status-A" class="text-sm font-medium text-red-500 hidden">... Listening</p>
                <button id="mic-btn-A"
                        class="mic-button bg-cyan-500 text-white p-3 rounded-full shadow-lg hover:shadow-xl focus:outline-none focus:ring-4 focus:ring-cyan-300"
                        aria-label="Start Recording"
                        disabled>
                    <!-- Microphone icon -->
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-mic"><path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path><path d="M19 10v2a7 7 0 0 1-14 0v-2"></path><line x1="12" y1="19" x2="12" y2="23"></line><line x1="8" y1="23" x2="16" y2="23"></line></svg>
                </button>
            </div>
        </div>

        <!-- Swap Button (Middle) -->
        <div class="flex justify-center items-center py-4 md:py-0">
            <button id="swap-btn"
                    class="bg-gray-200 text-gray-700 p-4 rounded-full shadow-md hover:bg-gray-300 transition duration-150 ease-in-out focus:outline-none focus:ring-4 focus:ring-gray-300"
                    aria-label="Swap Source and Target Languages">
                <!-- Swap icon (left/right arrows) -->
                <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-repeat"><polyline points="17 1 21 5 17 9"></polyline><path d="M3 11V9a4 4 0 0 1 4-4h14"></path><polyline points="7 23 3 19 7 15"></polyline><path d="M21 13v2a4 4 0 0 1-4 4H3"></path></svg>
            </button>
        </div>

        <!-- Panel B (Target Translation/Output) -->
        <div id="panel-B" class="p-4 bg-blue-50 border border-blue-200 rounded-lg">
            <h2 id="title-B" class="text-xl font-bold text-gray-700 mb-3"></h2>
            <textarea id="text-B"
                      rows="6"
                      class="w-full p-3 border border-blue-300 rounded-lg focus:ring-blue-500 focus:border-blue-500 resize-none text-gray-800 font-medium"
                      placeholder="The translation will appear here..."
                      readonly></textarea>
            
            <div class="flex justify-between items-center mt-3">
                 <div id="tts-loading" class="loading-indicator hidden">
                    <div class="spinner"></div>
                    <span>Generating Speech...</span>
                </div>
                <span class="text-sm font-medium text-transparent hidden md:inline">Placeholder</span> <!-- Spacer for alignment -->
                <button id="speak-btn-B"
                        class="speak-button bg-green-600 text-white font-semibold py-2 px-4 rounded-lg shadow-md hover:shadow-lg transition duration-150 ease-in-out focus:outline-none focus:ring-4 focus:ring-green-300 disabled:opacity-50"
                        aria-label="Speak Translation"
                        disabled>
                    Speak
                </button>
            </div>
        </div>

    </div>
    
    <p id="error-message" class="text-red-500 mt-4 text-center font-medium hidden">Microphone access denied or not supported.</p>

</div>

<script>
    // --- 1. Tooling and Constants Setup ---
    
    // UI Elements
    const textA = document.getElementById('text-A');
    const textB = document.getElementById('text-B');
    const titleA = document.getElementById('title-A');
    const titleB = document.getElementById('title-B');
    const micBtnA = document.getElementById('mic-btn-A');
    const speakBtnB = document.getElementById('speak-btn-B');
    const statusA = document.getElementById('status-A');
    const errorMessage = document.getElementById('error-message');
    const ttsLoading = document.getElementById('tts-loading');
    
    const sourceLangSelect = document.getElementById('source-language-select');
    const targetLangSelect = document.getElementById('target-language-select');
    const swapBtn = document.getElementById('swap-btn');
    const ttsApiToggle = document.getElementById('tts-api-toggle'); 

    // Consolidated Language List (7 languages)
    const LANGUAGES = [
        { code: 'en-US', name: 'English', voice: 'Puck' },
        { code: 'it-IT', name: 'Italian', voice: 'Aoede' }, 
        { code: 'fr-FR', name: 'French', voice: 'Charon' },
        { code: 'es-ES', name: 'Spanish', voice: 'Zephyr' },
        { code: 'ar-EG', name: 'Arabic (Egypt)', voice: 'Kore' },
        { code: 'bn-BD', name: 'Bengali', voice: 'Achird' },
        { code: 'tr-TR', name: 'Turkish', voice: 'Fenrir' }
    ];
    
    // Voices cache for browser TTS
    let browserVoices = [];
    
    // State variables
    let currentSourceCode = 'en-US';
    let currentTargetCode = 'it-IT'; 
    let useApiTts = false; 

    // --- FLAG FOR AUTO-PLAY FIX: Tracks if the user has triggered audio once ---
    let hasUserInteracted = false; 

    // Speech Recognition and State (recognition is now ephemeral, only exists during recording)
    let recognition = null;
    let isRecording = false;
    let isMicSupported = false;
    
    // --- Timeout ID for forced stop ---
    let recognitionTimeoutId = null; 
    
    // --- 2. Language Selector Initialization ---
    
    const populateLanguageSelectors = () => {
        sourceLangSelect.innerHTML = '';
        targetLangSelect.innerHTML = ''; 
        
        LANGUAGES.forEach(lang => {
            // Populate Source
            let optionA = document.createElement('option');
            optionA.value = lang.code;
            optionA.textContent = lang.name;
            sourceLangSelect.appendChild(optionA);

            // Populate Target
            let optionB = document.createElement('option');
            optionB.value = lang.code;
            optionB.textContent = lang.name;
            targetLangSelect.appendChild(optionB);
        });

        // Set initial selections
        sourceLangSelect.value = currentSourceCode;
        targetLangSelect.value = currentTargetCode;

        updateUI();
    };
    
    // Helper to get language details by code
    const getLangByCode = (code) => LANGUAGES.find(lang => lang.code === code);

    // --- 3. Core UI Update & State Management ---
    
    const updateUI = () => {
        const sourceLang = getLangByCode(currentSourceCode);
        const targetLang = getLangByCode(currentTargetCode);

        if (!sourceLang || !targetLang) return; 

        // 1. Update Panel A (Source)
        titleA.textContent = `${sourceLang.name} (Source)`;
        textA.placeholder = `Speak in ${sourceLang.name}, or type, to translate...`;
        micBtnA.setAttribute('aria-label', `Start Recording ${sourceLang.name}`);

        // 2. Update Panel B (Target)
        titleB.textContent = `${targetLang.name} (Target)`;
        textB.placeholder = `The ${targetLang.name} translation will appear here...`;
        speakBtnB.textContent = `Speak ${targetLang.name}`;
        speakBtnB.setAttribute('aria-label', `Speak Translation in ${targetLang.name}`);

        // 3. Clear and disable controls
        textA.value = '';
        textB.value = '';
        speakBtnB.disabled = true;
    };
    
    const handleSourceChange = () => {
        const newSourceCode = sourceLangSelect.value;
        if (newSourceCode === currentTargetCode) {
            targetLangSelect.value = currentSourceCode;
            currentTargetCode = currentSourceCode;
        }
        currentSourceCode = newSourceCode;
        updateUI();
    };

    const handleTargetChange = () => {
        const newTargetCode = targetLangSelect.value;
        if (newTargetCode === currentSourceCode) {
            sourceLangSelect.value = currentTargetCode;
            currentSourceCode = currentTargetCode;
        }
        currentTargetCode = newTargetCode;
        updateUI();
    };

    const swapLanguages = () => {
        const oldSource = currentSourceCode;
        const oldTarget = currentTargetCode;
        
        currentSourceCode = oldTarget;
        currentTargetCode = oldSource;
        
        sourceLangSelect.value = currentSourceCode;
        targetLangSelect.value = currentTargetCode;
        
        updateUI();
    };

    const handleTtsToggle = () => {
        useApiTts = ttsApiToggle.checked;
        console.log(`TTS Mode: ${useApiTts ? 'API' : 'Browser'}`);
    };
    
    // --- Centralized cleanup function for recognition events ---
    const cleanupRecognition = () => {
        if (recognitionTimeoutId) {
            clearTimeout(recognitionTimeoutId);
            recognitionTimeoutId = null;
        }
        isRecording = false;
        micBtnA.classList.remove('recording');
        statusA.classList.add('hidden');
    };


    // --- 4. Speech Recognition Lifecycle (Robust Cross-Platform Fix: New instance per use + Timeout) ---

    const checkMicSupport = () => {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

        if (!SpeechRecognition) {
            errorMessage.textContent = "Speech Recognition is not supported in this browser. Please use Chrome, Edge, or Safari.";
            errorMessage.classList.remove('hidden');
            micBtnA.disabled = true;
            isMicSupported = false;
        } else {
            micBtnA.disabled = false;
            isMicSupported = true;
        }
    }
    
    const startRecording = () => {
        if (!isMicSupported) return;

        // CRITICAL FIX: Teardown and create NEW instance to prevent 'service-not-allowed'
        if (recognition) {
            // Forcefully abort any lingering recognition process
            recognition.onend = null; 
            recognition.onerror = null;
            recognition.abort(); 
            recognition = null;
        }
        cleanupRecognition(); // Ensure timeout is cleared from previous run

        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        recognition = new SpeechRecognition();
        
        recognition.continuous = false; // Stop after a single, continuous utterance
        recognition.interimResults = false;
        recognition.lang = currentSourceCode; 

        recognition.onstart = () => {
            isRecording = true;
            micBtnA.classList.add('recording');
            statusA.textContent = '... Listening, Tap to Stop (7s limit)';
            statusA.classList.remove('hidden', 'text-red-500');
            statusA.classList.add('text-cyan-500');
            
            // Clear previous results before starting
            textA.value = '';
            textB.value = '';
            speakBtnB.disabled = true;
            errorMessage.classList.add('hidden'); // Clear error message
            
            // --- Implement a hard stop timeout (7000ms) ---
            recognitionTimeoutId = setTimeout(() => {
                if (isRecording) {
                    console.warn("Forcing recognition stop due to 7-second timeout.");
                    if (recognition) {
                         recognition.stop();
                    }
                }
            }, 7000); // 7 seconds should be enough for a phrase
        };

        recognition.onresult = (event) => {
            // Result received, clear timeout and let onend handle cleanup
            clearTimeout(recognitionTimeoutId); 
            
            const transcript = Array.from(event.results)
                .map(result => result[0].transcript)
                .join('');
            
            textA.value = transcript;
            
            if (transcript) {
                // Set the flag here as a result was received from a user interaction
                hasUserInteracted = true; 
                translateAndDisplay(transcript);
            }
        };

        recognition.onend = () => {
            // Final cleanup after the recognition session ends (either manually, by silence, or by timeout)
            cleanupRecognition(); 
        };

        recognition.onerror = (event) => {
            console.error('Speech Recognition Error:', event.error);
            
            // --- ANDROID FIX: Provide specific feedback for 'no-speech' which causes the 'stuck' feeling ---
            if (event.error === 'no-speech') {
                errorMessage.textContent = `No speech detected. Please try again and speak clearly into the microphone.`;
            } else {
                errorMessage.textContent = `Microphone Error: ${event.error}. Please ensure microphone access is allowed.`;
            }
            
            errorMessage.classList.remove('hidden');
            statusA.textContent = '... Error';
            statusA.classList.add('text-red-500');
            statusA.classList.remove('text-cyan-500');

            cleanupRecognition(); // Ensure cleanup on error
            
            // Critical: Abort the recognition object to force resource release
            if (recognition) {
                recognition.abort();
                recognition = null;
            }
        };
        
        // Final action: Start the new instance
        recognition.start();
    };

    const toggleRecording = () => {
        if (!isMicSupported) return;
        
        if (isRecording) {
            // Manual stop logic: let onend handle the cleanup
            if (recognition) {
                recognition.stop();
            }
        } else {
            // Start logic: handles instantiation inside
            startRecording();
        }
    };


    // --- 5. Translation Function (Uses Gemini API for translation) ---
    const translateAndDisplay = async (text) => {
        const sourceLang = getLangByCode(currentSourceCode);
        const targetLang = getLangByCode(currentTargetCode);

        if (!sourceLang || !targetLang) return; 

        textB.placeholder = `Translating to ${targetLang.name}...`;
        speakBtnB.disabled = true; // Disable while translating
        
        // Construct the dynamic system prompt and user query
        const systemPrompt = `You are a highly accurate, professional language translator. Your only job is to translate the provided text from ${sourceLang.name} into a grammatically correct, natural-sounding ${targetLang.name} translation. Respond with ONLY the translated ${targetLang.name} text, nothing else.`;
        const userQuery = `Translate the following ${sourceLang.name} phrase to ${targetLang.name}: "${text}"`;
        
        // API Configuration
        const apiKey = "AIzaSyBEQukhkVCX_4xed29ByJYxszIDn8IPNgM"; 
        const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`;

        if (!apiKey) {
            textB.value = "ERROR: API Key is missing. Translation will not work.";
            speakBtnB.disabled = false;
            return;
        }

        const payload = {
            contents: [{ parts: [{ text: userQuery }] }],
            systemInstruction: { parts: [{ text: systemPrompt }] },
        };
        
        let translatedText = "Translation failed or is unavailable.";
        
        try {
            const response = await fetch(apiUrl, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });

            if (!response.ok) {
                const errorData = await response.json();
                throw new Error(`HTTP error! Status: ${response.status}. Message: ${errorData.error?.message || 'Unknown API Error'}`);
            }
            
            const result = await response.json();
            const candidate = result.candidates?.[0];
            
            if (candidate && candidate.content?.parts?.[0]?.text) {
                translatedText = candidate.content.parts[0].text.trim(); 
            }
        } catch (error) {
            console.error("Translation API Request Failed:", error.message);
            translatedText = `Translation Error: ${error.message}`;
        }
        
        textB.value = translatedText;
        textB.placeholder = `The ${targetLang.name} translation will appear here...`;
        
        const translationSuccessful = !(translatedText.includes("Error") || translatedText.includes("unavailable"));

        // Always enable speech button if translation appears successful
        speakBtnB.disabled = !translationSuccessful;
        
        // --- Speak automatically ONLY IF the user has already interacted (Auto-play fix) ---
        if (translationSuccessful && hasUserInteracted) {
            speakTranslation(translatedText, currentTargetCode, true); 
        }
    };

    // --- 6. Text-to-Speech Utility Functions (Selective TTS) ---
    
    // Convert base64 string to ArrayBuffer
    function base64ToArrayBuffer(base64) {
        const binaryString = atob(base64);
        const len = binaryString.length;
        const bytes = new Uint8Array(len);
        for (let i = 0; i < len; i++) {
            bytes[i] = binaryString.charCodeAt(i);
        }
        return bytes.buffer;
    }

    // Convert PCM (raw audio data) to a standard WAV audio Blob
    function pcmToWav(pcm16, sampleRate) {
        const buffer = new ArrayBuffer(44 + pcm16.length * 2);
        const view = new DataView(buffer);
        
        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }

        // RIFF chunk descriptor (WAV header)
        writeString(view, 0, 'RIFF'); 
        view.setUint32(4, 36 + pcm16.length * 2, true); 
        writeString(view, 8, 'WAVE'); 

        // fmt sub-chunk
        writeString(view, 12, 'fmt '); 
        view.setUint32(16, 16, true); 
        view.setUint16(20, 1, true); // AudioFormat (1 for PCM)
        view.setUint16(22, 1, true); // NumChannels (1 mono)
        view.setUint32(24, sampleRate, true); 
        view.setUint32(28, sampleRate * 2, true); 
        view.setUint16(32, 2, true); 
        view.setUint16(34, 16, true); // BitsPerSample (16 bit)

        // data sub-chunk
        writeString(view, 36, 'data'); 
        view.setUint32(40, pcm16.length * 2, true); 

        // Write the PCM data
        let offset = 44;
        for (let i = 0; i < pcm16.length; i++) {
            view.setInt16(offset, pcm16[i], true);
            offset += 2;
        }

        return new Blob([buffer], { type: 'audio/wav' });
    }
    
    // --- 6A. Browser TTS Function ---
    const speakWithBrowserTTS = (text, targetCode) => {
        if (!('speechSynthesis' in window)) {
            errorMessage.textContent = "Browser TTS (Speech Synthesis) is not supported.";
            errorMessage.classList.remove('hidden');
            speakBtnB.disabled = false;
            return;
        }

        window.speechSynthesis.cancel();
        
        const utterance = new SpeechSynthesisUtterance(text);
        
        const langCodePrefix = targetCode.substring(0, 2);
        const voice = browserVoices.find(v => v.lang.startsWith(langCodePrefix) && v.localService); 
        
        if (voice) {
            utterance.voice = voice;
        } else {
            utterance.lang = targetCode; 
        }
        
        utterance.pitch = 1.0;
        utterance.rate = 1.0; 

        // Temporarily disable while speaking
        speakBtnB.disabled = true;
        
        // Timeout fallback to prevent button lock on iOS/Android
        let timeoutId = setTimeout(() => {
            console.warn("TTS Timeout: Forcing speak button re-enablement.");
            speakBtnB.disabled = false;
        }, 5000); 

        utterance.onend = () => {
            speakBtnB.disabled = false;
            clearTimeout(timeoutId); 
        };
        utterance.onerror = (e) => {
            console.warn("Browser TTS Error - could not synthesize speech:", e);
            speakBtnB.disabled = false;
            clearTimeout(timeoutId); 
        };
        
        window.speechSynthesis.speak(utterance);
    };

    // --- 6B. Gemini API TTS Function (High-Quality) ---
    const speakWithGeminiTTSApi = async (text, targetCode) => {
        const targetLang = getLangByCode(targetCode);
        if (!text || !targetLang) return;

        ttsLoading.classList.remove('hidden');
        speakBtnB.disabled = true;

        const voiceName = targetLang.voice;

        const apiKey = "AIzaSyBEQukhkVCX_4xed29ByJYxszIDn8IPNgM"; 
        const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${apiKey}`;

        if (!apiKey) {
            ttsLoading.classList.add('hidden');
            errorMessage.textContent = "TTS API Error: Key is missing. High-quality speech will not work.";
            errorMessage.classList.remove('hidden');
            speakBtnB.disabled = false; 
            return;
        }

        const payload = {
            contents: [{ 
                parts: [{ text: text }] 
            }],
            generationConfig: {
                responseModalities: ["AUDIO"],
                speechConfig: {
                    voiceConfig: {
                        prebuiltVoiceConfig: { voiceName: voiceName }
                    }
                }
            },
            model: "gemini-2.5-flash-preview-tts"
        };
        
        try {
            const response = await fetch(apiUrl, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });

            if (!response.ok) {
                const errorData = await response.json();
                throw new Error(`HTTP error! Status: ${response.status}. Message: ${errorData.error?.message || 'Unknown API Error'}`);
            }

            const result = await response.json();
            const part = result?.candidates?.[0]?.content?.parts?.[0];
            const audioData = part?.inlineData?.data;
            const mimeType = part?.inlineData?.mimeType;

            if (audioData && mimeType && mimeType.startsWith("audio/L16")) {
                const sampleRateMatch = mimeType.match(/rate=(\d+)/);
                if (!sampleRateMatch) {
                     throw new Error("Could not detect sample rate from MIME type.");
                }
                const sampleRate = parseInt(sampleRateMatch[1], 10);
                
                const pcmData = base64ToArrayBuffer(audioData);
                const pcm16 = new Int16Array(pcmData); 
                
                const wavBlob = pcmToWav(pcm16, sampleRate);
                const audioUrl = URL.createObjectURL(wavBlob);
                
                // Create audio element right before playing (best practice for iOS context)
                const audio = new Audio(audioUrl);
                
                // --- Start Playing & Manage Button State ---
                audio.play().catch(e => {
                    // CRITICAL: Catch play failure (e.g., user gesture block) and re-enable button
                    console.error("Audio play failed (gesture block?):", e);
                    speakBtnB.disabled = false; 
                });
                
                audio.onended = () => {
                    URL.revokeObjectURL(audioUrl); 
                    speakBtnB.disabled = false; // Re-enable on successful end
                };
                audio.onerror = (e) => {
                    console.error("Audio playback error:", e);
                    URL.revokeObjectURL(audioUrl); 
                    speakBtnB.disabled = false; // Re-enable on error
                }

            } else {
                throw new Error("Invalid or missing audio data in response.");
            }

        } catch (error) {
            console.error("Gemini TTS Request Failed:", error);
            errorMessage.textContent = `High-Quality Speech Error: ${error.message}. Check API key and quota.`;
            errorMessage.classList.remove('hidden');
            speakBtnB.disabled = false; // Important: Re-enable immediately on Fetch/Processing error

        } finally {
            ttsLoading.classList.add('hidden');
            // Final check to ensure button is not permanently disabled
            if (textB.value && speakBtnB.disabled) { 
                 speakBtnB.disabled = false;
            }
        }
    };
    
    // --- 6C. Main Speech Dispatcher ---
    const speakTranslation = (text, targetCode, isAuto = false) => {
        // Prevent action if there is no text to speak
        if (!text) return;
        
        ttsLoading.classList.add('hidden'); 
        
        if (useApiTts) {
            speakWithGeminiTTSApi(text, targetCode); 
        } else {
            speakWithBrowserTTS(text, targetCode); 
        }
    };

    // --- 7. Event Listeners & Initialization ---
    
    // Voice Input Button (Now uses the new toggleRecording logic)
    micBtnA.addEventListener('click', toggleRecording);
    
    // Text Input Detection (Allows translation when user types instead of speaking)
    let typingTimer;
    const doneTypingInterval = 1000; 
    
    textA.addEventListener('keyup', () => {
        clearTimeout(typingTimer);
        const text = textA.value.trim();
        if (text) {
            typingTimer = setTimeout(() => {
                if (text.length > 3) { 
                    // Manual typing also counts as user interaction for auto-speak
                    hasUserInteracted = true;
                    translateAndDisplay(text);
                }
            }, doneTypingInterval);
        } else {
            textB.value = '';
            speakBtnB.disabled = true;
        }
    });
    
    // Speak Button (Always attached to Panel B - now used for replay)
    speakBtnB.addEventListener('click', () => {
         // Manual interaction triggers the audio context and sets the user interaction flag
         hasUserInteracted = true; 
         speakTranslation(textB.value, currentTargetCode);
    });
    
    // Swap Button
    swapBtn.addEventListener('click', swapLanguages);

    // Language Selectors
    sourceLangSelect.addEventListener('change', handleSourceChange);
    targetLangSelect.addEventListener('change', handleTargetChange);
    
    // TTS API Toggle Listener
    ttsApiToggle.addEventListener('change', handleTtsToggle);

    // Load browser voices once they are available
    if ('speechSynthesis' in window) {
        window.speechSynthesis.onvoiceschanged = () => {
            browserVoices = window.speechSynthesis.getVoices();
        };
        // Load immediately if already available
        if (window.speechSynthesis.getVoices().length > 0) {
            browserVoices = window.speechSynthesis.getVoices();
        }
    }


    // Initial setup on page load
    window.onload = () => {
        populateLanguageSelectors();
        checkMicSupport(); // Only check for support once
    };
</script>
</body>
</html>
