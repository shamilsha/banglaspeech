<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Universal Bidirectional Voice Translator (High-Quality Bengali TTS)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <style>
        /* Custom styles for aesthetic appeal and responsiveness */
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f7fafc; /* Light gray background */
            display: flex;
            justify-content: center;
            align-items: flex-start;
            min-height: 100vh;
            padding: 20px;
        }
        .container-card {
            background-color: white;
            padding: 3rem 2rem;
            border-radius: 1.5rem;
            box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.1), 0 8px 10px -6px rgba(0, 0, 0, 0.1);
            max-width: 1000px;
            width: 100%;
            border-top: 5px solid #06B6D4;
        }
        .mic-button {
            transition: all 0.2s ease-in-out;
        }
        .mic-button:hover {
            box-shadow: 0 0 10px rgba(6, 182, 212, 0.5);
        }
        .mic-button.recording {
            animation: pulse-red 1.5s infinite;
            background-color: #EF4444;
            color: white;
        }
        @keyframes pulse-red {
            0% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(239, 68, 68, 0); }
            100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); }
        }
        .speak-button {
            transition: background-color 0.2s;
        }
        .speak-button:hover {
            background-color: #0c8c9e;
        }
        .select-wrapper {
            position: relative;
        }
        .select-wrapper::after {
            content: 'â–¼';
            position: absolute;
            right: 1rem;
            top: 50%;
            transform: translateY(-50%);
            pointer-events: none;
            color: #4a5568;
        }
        .language-select {
            appearance: none;
            padding-right: 2.5rem;
        }
        .loading-indicator {
            display: flex;
            align-items: center;
            justify-content: center;
            color: #06B6D4;
            font-weight: 600;
        }
        .spinner {
            border: 4px solid rgba(0, 0, 0, 0.1);
            border-left-color: #06B6D4;
            border-radius: 50%;
            width: 24px;
            height: 24px;
            animation: spin 1s linear infinite;
            margin-right: 8px;
        }
        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        /* Responsive layout for the panels */
        @media (min-width: 768px) {
            .panel-grid {
                grid-template-columns: 1fr 50px 1fr;
            }
        }
    </style>
</head>
<body>

<div class="container-card">
    <h1 class="text-3xl font-bold text-center text-gray-800 mb-2">Universal Voice Translator</h1>
    <p class="text-center text-gray-500 mb-6">Choose two languages and swap the direction instantly. High-quality Bengali speech is enabled!</p>

    <!-- Language Selectors (Primary and Secondary Groups) -->
    <div class="flex flex-col md:flex-row justify-center items-center mb-8 space-y-4 md:space-y-0 md:space-x-8">
        
        <!-- Primary Language Selector (English or Bengali) -->
        <div class="flex flex-col items-center space-y-2">
            <label for="primary-language-select" class="text-gray-700 font-medium">Primary Language (Group 1):</label>
            <div class="select-wrapper w-full max-w-xs">
                <select id="primary-language-select"
                        class="language-select w-full bg-white border border-gray-300 text-gray-700 py-3 px-4 pr-8 rounded-lg shadow-sm focus:outline-none focus:ring-2 focus:ring-cyan-500 focus:border-cyan-500">
                    <option value="en-US" data-name="English">English</option>
                    <option value="bn-BD" data-name="Bengali">Bengali</option>
                </select>
            </div>
        </div>

        <!-- Secondary Language Selector (French, Spanish, etc.) -->
        <div class="flex flex-col items-center space-y-2">
            <label for="secondary-language-select" class="text-gray-700 font-medium">Paired Language (Group 2):</label>
            <div class="select-wrapper w-full max-w-xs">
                <select id="secondary-language-select"
                        class="language-select w-full bg-white border border-gray-300 text-gray-700 py-3 px-4 pr-8 rounded-lg shadow-sm focus:outline-none focus:ring-2 focus:ring-cyan-500 focus:border-cyan-500">
                    <option value="fr-FR" data-name="French">French</option>
                    <option value="es-ES" data-name="Spanish">Spanish</option>
                    <option value="it-IT" data-name="Italian">Italian</option>
                    <option value="tr-TR" data-name="Turkish">Turkish</option>
                    <option value="ar-EG" data-name="Arabic">Arabic (Egypt)</option>
                </select>
            </div>
        </div>
    </div>
    
    <!-- Translation Panels and Controls -->
    <div class="grid grid-cols-1 md:grid-cols-3 gap-6 panel-grid">
        
        <!-- Panel A (Source) -->
        <div id="panel-A" class="p-4 bg-gray-50 border border-gray-200 rounded-lg">
            <h2 id="title-A" class="text-xl font-bold text-gray-700 mb-3">Language A (Source)</h2>
            <textarea id="text-A"
                      rows="6"
                      class="w-full p-3 border border-gray-300 rounded-lg focus:ring-cyan-500 focus:border-cyan-500 resize-none text-gray-700 font-medium"
                      placeholder="Speak here, or type, to translate..."></textarea>
            
            <div class="flex justify-between items-center mt-3">
                <p id="status-A" class="text-sm font-medium text-red-500 hidden">... Listening</p>
                <button id="mic-btn-A"
                        class="mic-button bg-cyan-500 text-white p-3 rounded-full shadow-lg hover:shadow-xl focus:outline-none focus:ring-4 focus:ring-cyan-300"
                        aria-label="Start Recording Language A"
                        disabled>
                    <!-- Microphone icon -->
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-mic"><path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path><path d="M19 10v2a7 7 0 0 1-14 0v-2"></path><line x1="12" y1="19" x2="12" y2="23"></line><line x1="8" y1="23" x2="16" y2="23"></line></svg>
                </button>
            </div>
        </div>

        <!-- Swap Button (Middle) -->
        <div class="flex justify-center items-center py-4 md:py-0">
            <button id="swap-btn"
                    class="bg-gray-200 text-gray-700 p-4 rounded-full shadow-md hover:bg-gray-300 transition duration-150 ease-in-out focus:outline-none focus:ring-4 focus:ring-gray-300"
                    aria-label="Swap Source and Target Languages">
                <!-- Swap icon (left/right arrows) -->
                <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-repeat"><polyline points="17 1 21 5 17 9"></polyline><path d="M3 11V9a4 4 0 0 1 4-4h14"></path><polyline points="7 23 3 19 7 15"></polyline><path d="M21 13v2a4 4 0 0 1-4 4H3"></path></svg>
            </button>
        </div>

        <!-- Panel B (Target) -->
        <div id="panel-B" class="p-4 bg-blue-50 border border-blue-200 rounded-lg">
            <h2 id="title-B" class="text-xl font-bold text-gray-700 mb-3">Language B (Target)</h2>
            <textarea id="text-B"
                      rows="6"
                      class="w-full p-3 border border-blue-300 rounded-lg focus:ring-blue-500 focus:border-blue-500 resize-none text-gray-800 font-medium"
                      placeholder="The translation will appear here..."
                      readonly></textarea>
            
            <div class="flex justify-between items-center mt-3">
                 <div id="tts-loading" class="loading-indicator hidden">
                    <div class="spinner"></div>
                    <span>Generating Speech...</span>
                </div>
                <span class="text-sm font-medium text-transparent hidden md:inline">Placeholder</span> <!-- Spacer for alignment -->
                <button id="speak-btn-B"
                        class="speak-button bg-green-600 text-white font-semibold py-2 px-4 rounded-lg shadow-md hover:shadow-lg transition duration-150 ease-in-out focus:outline-none focus:ring-4 focus:ring-green-300 disabled:opacity-50"
                        aria-label="Speak Translation"
                        disabled>
                    Speak
                </button>
            </div>
        </div>

    </div>
    
    <p id="error-message" class="text-red-500 mt-4 text-center font-medium hidden">Microphone access denied or not supported.</p>

</div>

<script>
    // --- 1. Tooling and Constants Setup ---
    
    // UI Elements
    const textA = document.getElementById('text-A');
    const textB = document.getElementById('text-B');
    const titleA = document.getElementById('title-A');
    const titleB = document.getElementById('title-B');
    const micBtnA = document.getElementById('mic-btn-A');
    const speakBtnB = document.getElementById('speak-btn-B');
    const statusA = document.getElementById('status-A');
    const errorMessage = document.getElementById('error-message');
    const ttsLoading = document.getElementById('tts-loading');
    
    const primaryLangSelect = document.getElementById('primary-language-select');
    const secondaryLangSelect = document.getElementById('secondary-language-select');
    const swapBtn = document.getElementById('swap-btn');

    const BENGALI_CODE = 'bn-BD';

    // State variables for the selected language pair
    let groupOneCode = 'en-US'; // Default to English
    let groupOneName = 'English';
    let groupTwoCode = 'fr-FR'; // Default to French
    let groupTwoName = 'French';
    
    // State variables for the current translation direction
    let currentSourceCode = groupOneCode;
    let currentTargetCode = groupTwoCode;
    let currentSourceName = groupOneName;
    let currentTargetName = groupTwoName;

    // Speech Recognition and State
    let recognition = null;
    let isRecording = false;

    // Helper function to get name from code
    const getLanguageName = (code, selector) => {
        const options = Array.from(selector.options);
        const option = options.find(opt => opt.value === code);
        return option ? option.getAttribute('data-name') : 'Unknown Language';
    };

    // --- 2. Core UI Update & State Management ---
    
    const updateDirectionState = () => {
        // Determine the source and target based on the current direction flag
        const isGroupOneSource = (currentSourceCode === groupOneCode || currentSourceCode === groupOneName); 
        
        if (isGroupOneSource) {
            currentSourceCode = groupOneCode;
            currentSourceName = groupOneName;
            currentTargetCode = groupTwoCode;
            currentTargetName = groupTwoName;
        } else {
            currentSourceCode = groupTwoCode;
            currentSourceName = groupTwoName;
            currentTargetCode = groupOneCode;
            currentTargetName = groupOneName;
        }
    };

    const updateUI = () => {
        // 1. Update the direction state based on the selected groups
        updateDirectionState();

        // 2. Update Panel A (Source)
        titleA.textContent = `${currentSourceName} (Source)`;
        textA.placeholder = `Speak in ${currentSourceName}, or type, to translate...`;
        micBtnA.setAttribute('aria-label', `Start Recording ${currentSourceName}`);

        // 3. Update Panel B (Target)
        titleB.textContent = `${currentTargetName} (Target)`;
        textB.placeholder = `The ${currentTargetName} translation will appear here...`;
        speakBtnB.textContent = `Speak ${currentTargetName}`;
        speakBtnB.setAttribute('aria-label', `Speak Translation in ${currentTargetName}`);

        // 4. Set the recognition language dynamically
        if (recognition) {
            // Note: Speech recognition support for Bengali may be limited depending on the browser/OS
            recognition.lang = currentSourceCode; 
        }

        // 5. Clear and disable controls initially
        textA.value = '';
        textB.value = '';
        speakBtnB.disabled = true;
    };
    
    const swapLanguages = () => {
        // Swap the current direction (Group 1 Source <-> Group 2 Source)
        const newSourceCode = currentTargetCode;
        const newTargetCode = currentSourceCode;

        currentSourceCode = newSourceCode;
        currentTargetCode = newTargetCode;
        
        currentSourceName = getLanguageName(currentSourceCode, Array.from(primaryLangSelect.options).find(opt => opt.value === currentSourceCode) ? primaryLangSelect : secondaryLangSelect);
        currentTargetName = getLanguageName(currentTargetCode, Array.from(secondaryLangSelect.options).find(opt => opt.value === currentTargetCode) ? secondaryLangSelect : primaryLangSelect);
        
        // Update the UI to reflect the new direction
        updateUI();
    };

    const handleLanguageChange = (isPrimary) => {
        const selector = isPrimary ? primaryLangSelect : secondaryLangSelect;
        const newCode = selector.value;
        const newName = selector.options[selector.selectedIndex].getAttribute('data-name');
        
        let oldCode = isPrimary ? groupOneCode : groupTwoCode;

        // Update Group 1 or Group 2 selection
        if (isPrimary) {
            groupOneCode = newCode;
            groupOneName = newName;
        } else {
            groupTwoCode = newCode;
            groupTwoName = newName;
        }
        
        // Logic to maintain the active source/target codes based on the change
        if (currentSourceCode === oldCode) {
            currentSourceCode = newCode;
            currentSourceName = newName;
        } else if (currentTargetCode === oldCode) {
            currentTargetCode = newCode;
            currentTargetName = newName;
        } else {
             // Reset direction to Group 1 -> Group 2 if something got out of sync
             currentSourceCode = groupOneCode;
             currentTargetCode = groupTwoCode;
        }

        updateUI();
    };


    // --- 3. Initialize Speech Recognition ---
    const initializeRecognition = () => {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

        if (!SpeechRecognition) {
            errorMessage.textContent = "Speech Recognition is not supported in this browser. Please use Chrome or Edge.";
            errorMessage.classList.remove('hidden');
            micBtnA.disabled = true;
            return;
        }

        recognition = new SpeechRecognition();
        recognition.continuous = false;
        recognition.interimResults = false;
        recognition.lang = currentSourceCode; // Set initial language

        recognition.onstart = () => {
            isRecording = true;
            micBtnA.classList.add('recording');
            statusA.classList.remove('hidden');
            textA.value = '';
            textB.value = '';
            speakBtnB.disabled = true;
        };

        recognition.onresult = (event) => {
            const transcript = Array.from(event.results)
                .map(result => result[0].transcript)
                .join('');
            
            textA.value = transcript;
            
            if (transcript) {
                // Call translation with current source/target codes
                translateAndDisplay(transcript, currentSourceCode, currentTargetCode, currentTargetName);
            }
        };

        recognition.onend = () => {
            isRecording = false;
            micBtnA.classList.remove('recording');
            statusA.classList.add('hidden');
        };

        recognition.onerror = (event) => {
            console.error('Speech Recognition Error:', event.error);
            errorMessage.textContent = `Microphone Error: ${event.error}. Please allow microphone access.`;
            errorMessage.classList.remove('hidden');
            micBtnA.classList.remove('recording');
            statusA.classList.add('hidden');
            isRecording = false;
        };
        
        // Wait until all initial setup is done before enabling mic
        setTimeout(() => {
            micBtnA.disabled = false;
        }, 500); 
    };

    // --- 4. Translation Function (Uses Gemini API) ---
    const translateAndDisplay = async (text, sourceCode, targetCode, targetName) => {
        textB.placeholder = `Translating to ${targetName}...`;
        
        // Determine the source/target names accurately for the prompt
        const srcName = currentSourceName;
        const tgtName = currentTargetName;
        
        // Construct the dynamic system prompt and user query
        const systemPrompt = `You are a highly accurate, professional language translator. Your only job is to translate the provided text from ${srcName} into a grammatically correct, natural-sounding ${tgtName} translation. Respond with ONLY the translated ${tgtName} text, nothing else.`;
        const userQuery = `Translate the following ${srcName} phrase to ${tgtName}: "${text}"`;
        
        // API Configuration (Your key should already be here)
        const apiKey = "AIzaSyBEQukhkVCX_4xed29ByJYxszIDn8IPNgM"; 
        const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`;

        if (!apiKey) {
            textB.value = "ERROR: API Key is missing. Please edit the code to include your Gemini API Key.";
            speakBtnB.disabled = true;
            console.error("API Key Missing.");
            return;
        }

        const payload = {
            contents: [{ parts: [{ text: userQuery }] }],
            systemInstruction: { parts: [{ text: systemPrompt }] },
        };
        
        let translatedText = "Translation failed or is unavailable.";
        
        try {
            const response = await fetch(apiUrl, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });

            if (!response.ok) {
                const errorData = await response.json();
                throw new Error(`HTTP error! Status: ${response.status}. Message: ${errorData.error?.message || 'Unknown API Error'}`);
            }
            
            const result = await response.json();
            const candidate = result.candidates?.[0];
            
            if (candidate && candidate.content?.parts?.[0]?.text) {
                translatedText = candidate.content.parts[0].text.trim(); 
            }
        } catch (error) {
            console.error("Translation API Request Failed:", error.message);
            translatedText = `Translation Error: ${error.message}`;
        }
        
        textB.value = translatedText;
        textB.placeholder = `The ${currentTargetName} translation will appear here...`;
        
        // Check for success
        const translationSuccessful = !(translatedText.includes("Error") || translatedText.includes("unavailable"));

        // Enable speech button only if translation appears successful (for manual replay)
        speakBtnB.disabled = !translationSuccessful;
        
        // --- Speak automatically if successful ---
        if (translationSuccessful) {
            speakTranslation(translatedText, currentTargetCode);
        }
    };

    // --- 5. Text-to-Speech Utility Functions (for PCM to WAV conversion) ---
    
    // Convert base64 string to ArrayBuffer
    function base64ToArrayBuffer(base64) {
        const binaryString = atob(base64);
        const len = binaryString.length;
        const bytes = new Uint8Array(len);
        for (let i = 0; i < len; i++) {
            bytes[i] = binaryString.charCodeAt(i);
        }
        return bytes.buffer;
    }

    // Convert PCM (raw audio data) to a standard WAV audio Blob
    function pcmToWav(pcm16, sampleRate) {
        const buffer = new ArrayBuffer(44 + pcm16.length * 2);
        const view = new DataView(buffer);
        
        // Helper function to write bytes
        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }

        // RIFF chunk descriptor
        writeString(view, 0, 'RIFF'); // ChunkID
        view.setUint32(4, 36 + pcm16.length * 2, true); // ChunkSize
        writeString(view, 8, 'WAVE'); // Format

        // fmt sub-chunk
        writeString(view, 12, 'fmt '); // Subchunk1ID
        view.setUint32(16, 16, true); // Subchunk1Size (16 for PCM)
        view.setUint16(20, 1, true); // AudioFormat (1 for PCM)
        view.setUint16(22, 1, true); // NumChannels (1 mono)
        view.setUint32(24, sampleRate, true); // SampleRate
        view.setUint32(28, sampleRate * 2, true); // ByteRate (SampleRate * NumChannels * BitsPerSample/8)
        view.setUint16(32, 2, true); // BlockAlign (NumChannels * BitsPerSample/8)
        view.setUint16(34, 16, true); // BitsPerSample (16 bit)

        // data sub-chunk
        writeString(view, 36, 'data'); // Subchunk2ID
        view.setUint32(40, pcm16.length * 2, true); // Subchunk2Size (NumSamples * NumChannels * BitsPerSample/8)

        // Write the PCM data
        let offset = 44;
        for (let i = 0; i < pcm16.length; i++) {
            view.setInt16(offset, pcm16[i], true);
            offset += 2;
        }

        return new Blob([buffer], { type: 'audio/wav' });
    }

    // --- 6. Text-to-Speech (Speaking the Translation) ---
    
    // Function to handle the actual speaking logic
    const speakTranslation = async (text, targetCode) => {
        if (!text) return;

        // If the target is Bengali, use the high-quality Gemini TTS model
        if (targetCode === BENGALI_CODE) {
            await speakWithGeminiTTS(text);
        } else {
            // Otherwise, use the standard browser TTS for other languages
            speakWithBrowserTTS(text, targetCode);
        }
    };
    
    // Browser TTS implementation (for non-Bengali languages)
    const speakWithBrowserTTS = (text, targetCode) => {
        if (!('speechSynthesis' in window)) {
            errorMessage.textContent = "Text-to-Speech is not supported in this browser.";
            errorMessage.classList.remove('hidden');
            return;
        }
        
        const utterance = new SpeechSynthesisUtterance(text);
        
        const voices = window.speechSynthesis.getVoices();
        const targetVoice = voices.find(voice => voice.lang === targetCode || voice.lang.startsWith(targetCode.substring(0, 2)));
        
        if (targetVoice) {
            utterance.voice = targetVoice;
        } else {
            utterance.lang = targetCode; 
        }
        
        if (window.speechSynthesis.speaking) {
            window.speechSynthesis.cancel();
        }
        
        window.speechSynthesis.speak(utterance);
    };

    // Gemini TTS implementation (for high-quality Bengali)
    const speakWithGeminiTTS = async (text) => {
        ttsLoading.classList.remove('hidden');
        speakBtnB.disabled = true;

        const apiKey = ""; 
        const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${apiKey}`;

        if (!apiKey) {
            ttsLoading.classList.add('hidden');
            errorMessage.textContent = "TTS Error: API Key is missing for Bengali speech generation.";
            errorMessage.classList.remove('hidden');
            return;
        }

        const payload = {
            contents: [{ 
                parts: [{ text: text }] 
            }],
            generationConfig: {
                responseModalities: ["AUDIO"],
                // Using a natural language hint for high-quality Bengali voice
                speechConfig: {
                    voiceConfig: {
                        prebuiltVoiceConfig: { voiceName: "Achird" } // Achird is a friendly-sounding voice
                    }
                }
            },
            model: "gemini-2.5-flash-preview-tts"
        };
        
        try {
            const response = await fetch(apiUrl, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });

            if (!response.ok) {
                const errorData = await response.json();
                throw new Error(`HTTP error! Status: ${response.status}. Message: ${errorData.error?.message || 'Unknown API Error'}`);
            }

            const result = await response.json();
            const part = result?.candidates?.[0]?.content?.parts?.[0];
            const audioData = part?.inlineData?.data;
            const mimeType = part?.inlineData?.mimeType;

            if (audioData && mimeType && mimeType.startsWith("audio/L16")) {
                const sampleRateMatch = mimeType.match(/rate=(\d+)/);
                if (!sampleRateMatch) {
                     throw new Error("Could not detect sample rate from MIME type.");
                }
                const sampleRate = parseInt(sampleRateMatch[1], 10);
                
                const pcmData = base64ToArrayBuffer(audioData);
                const pcm16 = new Int16Array(pcmData); // API returns signed PCM16
                
                const wavBlob = pcmToWav(pcm16, sampleRate);
                const audioUrl = URL.createObjectURL(wavBlob);
                
                const audio = new Audio(audioUrl);
                audio.play();
                audio.onended = () => {
                    URL.revokeObjectURL(audioUrl); // Clean up the URL object
                    speakBtnB.disabled = false;
                };

            } else {
                throw new Error("Invalid or missing audio data in response.");
            }

        } catch (error) {
            console.error("Gemini TTS Request Failed:", error);
            errorMessage.textContent = `High-Quality Speech Error: ${error.message}. Falling back to standard voice.`;
            errorMessage.classList.remove('hidden');
            speakWithBrowserTTS(text, BENGALI_CODE); // Fallback

        } finally {
            ttsLoading.classList.add('hidden');
            speakBtnB.disabled = false;
        }
    };


    // --- 7. Event Listeners & Initialization ---
    
    // Voice Input Button (Always attached to Panel A)
    micBtnA.addEventListener('click', () => {
        if (isRecording) {
            recognition.stop();
        } else {
            // Re-set the recognition language just before starting
            if(recognition) {
                 recognition.lang = currentSourceCode;
            }
            recognition.start();
        }
    });
    
    // Text Input Detection (Allows translation when user types instead of speaking)
    let typingTimer;
    const doneTypingInterval = 1000; // 1 second
    
    textA.addEventListener('keyup', () => {
        clearTimeout(typingTimer);
        const text = textA.value.trim();
        if (text) {
            typingTimer = setTimeout(() => {
                if (text.length > 3) { 
                    translateAndDisplay(text, currentSourceCode, currentTargetCode, currentTargetName);
                }
            }, doneTypingInterval);
        } else {
            textB.value = '';
            speakBtnB.disabled = true;
        }
    });
    
    // Speak Button (Always attached to Panel B - now used for replay)
    speakBtnB.addEventListener('click', () => {
         // Replay the current translation using the high-quality/standard function
         speakTranslation(textB.value, currentTargetCode);
    });
    
    // Swap Button
    swapBtn.addEventListener('click', swapLanguages);

    // Language Selectors
    primaryLangSelect.addEventListener('change', () => handleLanguageChange(true));
    secondaryLangSelect.addEventListener('change', () => handleLanguageChange(false));


    // Initial setup on page load
    window.onload = () => {
        handleLanguageChange(true); 
        handleLanguageChange(false); 
        updateUI(); 
        initializeRecognition();

        // Pre-load browser voices to prevent delay on first use (if needed)
        if ('speechSynthesis' in window) {
            if (window.speechSynthesis.getVoices().length === 0) {
                 window.speechSynthesis.onvoiceschanged = initializeRecognition;
            }
        }
    };
</script>
</body>
</html>
